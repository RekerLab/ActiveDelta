# Imports
import os
import abc
import math
import shutil
import tempfile
import numpy as np
import pandas as pd
import chemprop
from rdkit import Chem
from rdkit.Chem import AllChem
from sklearn import metrics
from scipy import stats as stats
from sklearn.model_selection import KFold
from sklearn.ensemble import RandomForestRegressor as RF

datasets = ['CHEMBL1267245',
 'CHEMBL1267247',
 'CHEMBL1267248',
 'CHEMBL1267250',
 'CHEMBL3705282',
 'CHEMBL3705362',
 'CHEMBL3705464',
 'CHEMBL3705542',
 'CHEMBL3705647',
 'CHEMBL3705655',
 'CHEMBL3705790',
 'CHEMBL3705791',
 'CHEMBL3705813',
 'CHEMBL3705899',
 'CHEMBL3705924',
 'CHEMBL3705960',
 'CHEMBL3705971',
 'CHEMBL3706037',
 'CHEMBL3706089',
 'CHEMBL3706310',
 'CHEMBL3706316',
 'CHEMBL3706373',
 'CHEMBL3707951',
 'CHEMBL3707962',
 'CHEMBL3721139',
 'CHEMBL3734252',
 'CHEMBL3734552',
 'CHEMBL3880337',
 'CHEMBL3880338',
 'CHEMBL3880340',
 'CHEMBL3887033',
 'CHEMBL3887061',
 'CHEMBL3887063',
 'CHEMBL3887188',
 'CHEMBL3887296',
 'CHEMBL3887679',
 'CHEMBL3887757',
 'CHEMBL3887758',
 'CHEMBL3887759',
 'CHEMBL3887796',
 'CHEMBL3887849',
 'CHEMBL3887887',
 'CHEMBL3887945',
 'CHEMBL3887987',
 'CHEMBL3888087',
 'CHEMBL3888190',
 'CHEMBL3888194',
 'CHEMBL3888268',
 'CHEMBL3888295',
 'CHEMBL3888825',
 'CHEMBL3888966',
 'CHEMBL3888977',
 'CHEMBL3888980',
 'CHEMBL3889082',
 'CHEMBL3889083',
 'CHEMBL3889139']
 
models = [DeepDelta(), Trad_ChemProp(), Trad_RF(), 'Random_Selection']

random_split_datasets = ['Random_Split_For_AL_1', 'Random_Split_For_AL_2', 'Random_Split_For_AL_3']

# number of active learning iterations
start_iteration = 0
final_iteration = 200  

for random_split_dataset in random_split_datasets:

  for dataset in datasets:
      
    # Currently set to only run for the first random split of the Data
    training_dataframe = pd.read_csv("../Datasets/{}/{}_train_round_{}.csv".format(random_split_dataset, dataset, start_iteration))
    learning_dataframe = pd.read_csv("../Datasets/{}/{}_learning_round_{}.csv".format(random_split_dataset, dataset, start_iteration))

    for model in models:

      for iter in range(start_iteration, final_iteration):

        if str(model) != 'Random_Selection': # Using model prediction for selection

          ################
          ### Training ###
          ################

          training_dataframe = training_dataframe.reset_index(drop=True)
          x = training_dataframe[training_dataframe.columns[0]]
          y = training_dataframe[training_dataframe.columns[1]]

          model.fit(x,y) # Train model on the training dataset

          ##################
          ### Prediction ###
          ##################

          x_l_df = learning_dataframe[learning_dataframe.columns[0]]
          y_l_df = learning_dataframe[learning_dataframe.columns[1]]

          if str(model) != 'DeepDelta5': # Traditional models (RF and ChemProp)
            predictions = model.predict_single(x_l_df) # predict
            
          else: # ActiveDelta learning
            max_train_index = y.idxmax() # Get maximum training datapoint
            predictions = model.predict2(pd.DataFrame([x[max_train_index]]), x_l_df) # predict

          # Save data
          results = [y_l_df, predictions]

          ##########################################
          ### Active Learning Molecule Selection ###
          ##########################################

          preds = pd.DataFrame(results).T
          preds.columns =['Y', 'Y_Pred']
          preds['SMILES'] = learning_dataframe['SMILES'].tolist()

          # Add top prediction to training dataset
          SMILES = pd.DataFrame(preds.nlargest(1, 'Y_Pred')['SMILES'])
          TRUE = pd.DataFrame(preds.nlargest(1, 'Y_Pred')['Y'])
          PRED = pd.DataFrame(preds.nlargest(1, 'Y_Pred')['Y_Pred'])
          AL_ITER = pd.DataFrame({'Iteration': [iter+1]}, index=list(SMILES.index.values))
          top_molecule = pd.concat([SMILES, TRUE, PRED, AL_ITER], axis=1)
          training_dataframe = pd.concat([training_dataframe, top_molecule])

          # Remove top prediction from learning dataset
          learning_dataframe = pd.merge(learning_dataframe, top_molecule.drop(columns=['Y_Pred', 'Iteration']), on=['SMILES','Y'], how='outer', indicator=True).query("_merge != 'both'").drop('_merge', axis=1).reset_index(drop=True)

        else: # Meaning random selection of a datapoint
          random_molecule = learning_dataframe.sample()
          AL_ITER = pd.DataFrame({'Iteration': [iter+1]}, index=list(random_molecule.index.values))
          top_molecule = pd.concat([random_molecule, AL_ITER], axis=1)
          training_dataframe = pd.concat([training_dataframe, top_molecule])
          
          # Remove matching random molecule from learning dataset
          learning_dataframe = pd.merge(learning_dataframe, top_molecule.drop(columns=['Iteration']), on=['SMILES','Y'], how='outer', indicator=True).query("_merge != 'both'").drop('_merge', axis=1).reset_index(drop=True)

      # Save training dataframe
      training_dataframe.to_csv('{}_train_round_{}_{}_{}.csv'.format(dataset, str(model), iter + 1, random_split_dataset), index = False)
      learning_dataframe.to_csv('{}_learning_round_{}_{}_{}.csv'.format(dataset, str(model), iter + 1, random_split_dataset), index = False)